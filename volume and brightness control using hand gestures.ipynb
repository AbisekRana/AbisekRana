{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034d5cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui\n",
    "import screen_brightness_control as sbcq\n",
    "import numpy as np\n",
    "from math import hypot\n",
    "from google.protobuf.json_format import MessageToDict\n",
    "\n",
    "Draw = mp.solutions.drawing_utils\n",
    "# Initializing the Model\n",
    "mpHands = mp.solutions.hands\n",
    "hands = mpHands.Hands(\n",
    "    static_image_mode=False,\n",
    "    model_complexity=1,\n",
    "    min_detection_confidence=0.75,\n",
    "    min_tracking_confidence=0.75,\n",
    "    max_num_hands=2)\n",
    "\n",
    "# Start capturing video from webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Read video frame by frame\n",
    "    success, img = cap.read()\n",
    "\n",
    "    # Flip the image(frame)\n",
    "    img = cv2.flip(img, 1)\n",
    "\n",
    "    # Convert BGR image to RGB image\n",
    "    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the RGB image\n",
    "    results = hands.process(imgRGB)\n",
    "    # If hands are present in image(frame)\n",
    "    if results.multi_hand_landmarks:\n",
    "\n",
    "        # Both Hands are present in image(frame)\n",
    "        if len(results.multi_handedness) == 2:\n",
    "            # Display 'Both Hands' on the image\n",
    "            cv2.putText(img, 'Both Hands are there', (250, 50),\n",
    "                        cv2.FONT_HERSHEY_COMPLEX,\n",
    "                        0.9, (0, 255, 0), 2)\n",
    "\n",
    "        # If any hand present\n",
    "        else:\n",
    "            for i in results.multi_handedness:\n",
    "\n",
    "                # Return whether it is Right or Left Hand\n",
    "                label = MessageToDict(i)['classification'][0]['label']\n",
    "\n",
    "                if label == 'Left':\n",
    "                    landmarkList = []\n",
    "                    # if hands are present in image(frame)\n",
    "                    if results.multi_hand_landmarks:\n",
    "                        # detect handmarks\n",
    "                        for handlm in results.multi_hand_landmarks:\n",
    "                            for _id, landmarks in enumerate(handlm.landmark):\n",
    "                                # store height and width of image\n",
    "                                height, width, color_channels = img.shape\n",
    "\n",
    "                                # calculate and append x, y coordinates\n",
    "                                # of handmarks from image(frame) to lmList\n",
    "                                x, y = int(landmarks.x * width), int(landmarks.y * height)\n",
    "                                landmarkList.append([_id, x, y])\n",
    "\n",
    "                            # draw Landmarks\n",
    "                            Draw.draw_landmarks(img, handlm,\n",
    "                                                mpHands.HAND_CONNECTIONS)\n",
    "\n",
    "                    # If landmarks list is not empty\n",
    "                    if landmarkList != []:\n",
    "                        # store x,y coordinates of (tip of) thumb\n",
    "                        x_1, y_1 = landmarkList[4][1], landmarkList[4][2]\n",
    "\n",
    "                        # store x,y coordinates of (tip of) index finger\n",
    "                        x_2, y_2 = landmarkList[8][1], landmarkList[8][2]\n",
    "\n",
    "                        # draw circle on thumb and index finger tip\n",
    "                        cv2.circle(img, (x_1, y_1), 7, (0, 255, 0), cv2.FILLED)\n",
    "                        cv2.circle(img, (x_2, y_2), 7, (0, 255, 0), cv2.FILLED)\n",
    "\n",
    "                        # draw line from tip of thumb to tip of index finger\n",
    "                        cv2.line(img, (x_1, y_1), (x_2, y_2), (0, 255, 0), 3)\n",
    "\n",
    "                        # calculate square root of the sum of\n",
    "                        # squares of the specified arguments.\n",
    "                    L = hypot(x_2 - x_1, y_2 - y_1)\n",
    "                    if L > 50:\n",
    "                        pyautogui.press(\"volumeup\")\n",
    "                    else:\n",
    "                        pyautogui.press(\"volumedown\")\n",
    "\n",
    "                if label == 'Right':\n",
    "                    landmarkList = []\n",
    "                    if results.multi_hand_landmarks:\n",
    "                        for handlm in results.multi_hand_landmarks:\n",
    "                            for _id, landmarks in enumerate(handlm.landmark):\n",
    "                                height, width, color_channels = img.shape\n",
    "                                x, y = int(landmarks.x * width), int(landmarks.y * height)\n",
    "                                landmarkList.append([_id, x, y])\n",
    "                            Draw.draw_landmarks(img, handlm,\n",
    "                                                mpHands.HAND_CONNECTIONS)\n",
    "                    if landmarkList:\n",
    "                        x_1, y_1 = landmarkList[4][1], landmarkList[4][2]\n",
    "                        x_2, y_2 = landmarkList[8][1], landmarkList[8][2]\n",
    "                        cv2.circle(img, (x_1, y_1), 7, (0, 255, 0), cv2.FILLED)\n",
    "                        cv2.circle(img, (x_2, y_2), 7, (0, 255, 0), cv2.FILLED)\n",
    "                        cv2.line(img, (x_1, y_1), (x_2, y_2), (0, 255, 0), 3)\n",
    "                        L = hypot(x_2 - x_1, y_2 - y_1)\n",
    "\n",
    "                        # 1-D linear interpolant to a function\n",
    "                        # with given discrete data points\n",
    "                        # (Hand range 15 - 220, Brightness\n",
    "                        # range 0 - 100), evaluated at length.\n",
    "                        b_level = np.interp(L, [15, 220], [0, 100])\n",
    "\n",
    "                        # set brightness\n",
    "                        sbc.set_brightness(int(b_level))\n",
    "    # Display Video and when 'q'\n",
    "    # is entered, destroy the window\n",
    "    cv2.imshow(\"Image\", img)\n",
    "    if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbc5625",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
